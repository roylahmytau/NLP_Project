Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:03<00:14,  3.57s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:12,  4.05s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.20s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:16<00:00,  2.60s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]
  0%|          | 0/40 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  2%|▎         | 1/40 [00:06<04:13,  6.50s/it]                                                2%|▎         | 1/40 [00:06<04:13,  6.50s/it]  5%|▌         | 2/40 [00:10<03:06,  4.92s/it]                                                5%|▌         | 2/40 [00:10<03:06,  4.92s/it]  8%|▊         | 3/40 [00:14<02:52,  4.66s/it]                                                8%|▊         | 3/40 [00:14<02:52,  4.66s/it] 10%|█         | 4/40 [00:18<02:33,  4.25s/it]                                               10%|█         | 4/40 [00:18<02:33,  4.25s/it] 12%|█▎        | 5/40 [00:22<02:30,  4.31s/it]                                               12%|█▎        | 5/40 [00:22<02:30,  4.31s/it] 15%|█▌        | 6/40 [00:26<02:20,  4.13s/it]                                               15%|█▌        | 6/40 [00:26<02:20,  4.13s/it] 18%|█▊        | 7/40 [00:31<02:26,  4.42s/it]                                               18%|█▊        | 7/40 [00:31<02:26,  4.42s/it] 20%|██        | 8/40 [00:35<02:13,  4.17s/it]                                               20%|██        | 8/40 [00:35<02:13,  4.17s/it] 22%|██▎       | 9/40 [00:39<02:09,  4.16s/it]                                               22%|██▎       | 9/40 [00:39<02:09,  4.16s/it] 25%|██▌       | 10/40 [00:42<01:59,  3.99s/it]                                                25%|██▌       | 10/40 [00:42<01:59,  3.99s/it] 28%|██▊       | 11/40 [00:47<02:02,  4.21s/it]                                                28%|██▊       | 11/40 [00:47<02:02,  4.21s/it] 30%|███       | 12/40 [00:51<01:53,  4.04s/it]                                                30%|███       | 12/40 [00:51<01:53,  4.04s/it] 32%|███▎      | 13/40 [00:55<01:51,  4.13s/it]                                                32%|███▎      | 13/40 [00:55<01:51,  4.13s/it] 35%|███▌      | 14/40 [00:59<01:44,  4.04s/it]                                                35%|███▌      | 14/40 [00:59<01:44,  4.04s/it] 38%|███▊      | 15/40 [01:03<01:44,  4.17s/it]                                                38%|███▊      | 15/40 [01:03<01:44,  4.17s/it] 40%|████      | 16/40 [01:07<01:36,  4.01s/it]                                                40%|████      | 16/40 [01:07<01:36,  4.01s/it] 42%|████▎     | 17/40 [01:11<01:33,  4.08s/it]                                                42%|████▎     | 17/40 [01:11<01:33,  4.08s/it] 45%|████▌     | 18/40 [01:15<01:27,  3.96s/it]                                                45%|████▌     | 18/40 [01:15<01:27,  3.96s/it] 48%|████▊     | 19/40 [01:20<01:28,  4.20s/it]                                                48%|████▊     | 19/40 [01:20<01:28,  4.20s/it] 50%|█████     | 20/40 [01:23<01:20,  4.02s/it]                                                50%|█████     | 20/40 [01:23<01:20,  4.02s/it] 52%|█████▎    | 21/40 [01:28<01:17,  4.10s/it]                                                52%|█████▎    | 21/40 [01:28<01:17,  4.10s/it] 55%|█████▌    | 22/40 [01:31<01:12,  4.02s/it]                                                55%|█████▌    | 22/40 [01:31<01:12,  4.02s/it] 57%|█████▊    | 23/40 [01:36<01:09,  4.10s/it]                                                57%|█████▊    | 23/40 [01:36<01:09,  4.10s/it] 60%|██████    | 24/40 [01:39<01:03,  4.00s/it]                                                60%|██████    | 24/40 [01:39<01:03,  4.00s/it] 62%|██████▎   | 25/40 [01:44<01:00,  4.06s/it]                                                62%|██████▎   | 25/40 [01:44<01:00,  4.06s/it] 65%|██████▌   | 26/40 [01:47<00:54,  3.93s/it]                                                65%|██████▌   | 26/40 [01:47<00:54,  3.93s/it] 68%|██████▊   | 27/40 [01:51<00:52,  4.00s/it]                                                68%|██████▊   | 27/40 [01:51<00:52,  4.00s/it] 70%|███████   | 28/40 [01:55<00:47,  3.95s/it]                                                70%|███████   | 28/40 [01:55<00:47,  3.95s/it] 72%|███████▎  | 29/40 [02:00<00:46,  4.26s/it]                                                72%|███████▎  | 29/40 [02:00<00:46,  4.26s/it] 75%|███████▌  | 30/40 [02:04<00:40,  4.08s/it]                                                75%|███████▌  | 30/40 [02:04<00:40,  4.08s/it] 78%|███████▊  | 31/40 [02:08<00:37,  4.15s/it]                                                78%|███████▊  | 31/40 [02:08<00:37,  4.15s/it] 80%|████████  | 32/40 [02:12<00:33,  4.16s/it]                                                80%|████████  | 32/40 [02:12<00:33,  4.16s/it] 82%|████████▎ | 33/40 [02:16<00:28,  4.11s/it]                                                82%|████████▎ | 33/40 [02:16<00:28,  4.11s/it] 85%|████████▌ | 34/40 [02:20<00:23,  3.96s/it]                                                85%|████████▌ | 34/40 [02:20<00:23,  3.96s/it] 88%|████████▊ | 35/40 [02:24<00:20,  4.01s/it]                                                88%|████████▊ | 35/40 [02:24<00:20,  4.01s/it] 90%|█████████ | 36/40 [02:28<00:15,  3.96s/it]                                                90%|█████████ | 36/40 [02:28<00:15,  3.96s/it] 92%|█████████▎| 37/40 [02:33<00:12,  4.14s/it]                                                92%|█████████▎| 37/40 [02:33<00:12,  4.14s/it] 95%|█████████▌| 38/40 [02:36<00:08,  4.01s/it]                                                95%|█████████▌| 38/40 [02:36<00:08,  4.01s/it] 98%|█████████▊| 39/40 [02:40<00:04,  4.03s/it]                                                98%|█████████▊| 39/40 [02:40<00:04,  4.03s/it]100%|██████████| 40/40 [02:44<00:00,  3.92s/it]                                               100%|██████████| 40/40 [02:44<00:00,  3.92s/it]                                               100%|██████████| 40/40 [02:50<00:00,  3.92s/it]100%|██████████| 40/40 [02:50<00:00,  4.27s/it]
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:03,  1.23it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:01<00:02,  1.31it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:02<00:01,  1.34it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:02<00:00,  1.47it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.91it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.61it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Calculating perplexity:   0%|          | 0/5 [00:00<?, ?it/s]Calculating perplexity:  20%|██        | 1/5 [00:00<00:00,  4.75it/s]Calculating perplexity:  60%|██████    | 3/5 [00:00<00:00,  8.62it/s]Calculating perplexity: 100%|██████████| 5/5 [00:00<00:00, 10.11it/s]Calculating perplexity: 100%|██████████| 5/5 [00:00<00:00,  9.22it/s]
Traceback (most recent call last):
  File "/workspace/NLP_Project/benchmark_model.py", line 652, in <module>
    main()
  File "/workspace/NLP_Project/benchmark_model.py", line 617, in main
    glue_results = run_glue_benchmark(model, tokenizer, args.glue_task, args.max_samples, args.batch_size)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/benchmark_model.py", line 414, in run_glue_benchmark
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/peft/peft_model.py", line 1973, in generate
    outputs = self.base_model.generate(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2539, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2870, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 940, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1064, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 410, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 260, in forward
    hidden_states, _ = self.self_attn(
                       ^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 216, in forward
    attn_output, attn_weights = attention_interface(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py", line 62, in sdpa_attention_forward
    key = repeat_kv(key, module.num_key_value_groups)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/NLP_Project/.venv/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py", line 25, in repeat_kv
    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
