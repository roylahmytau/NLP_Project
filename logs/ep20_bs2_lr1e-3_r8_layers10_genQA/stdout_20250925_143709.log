Loading data...
Successfully loaded 100 items from JSON file
Loaded 100 generated QA snippets from outputs/qa_1_2048_fixed
Loaded 100 examples
Creating model...
Trainable parameters: 21,823,488
Total parameters: 4,739,675,136
Trainable %: 0.46%
Starting training...
Total training steps: 120
==================================================

--- Starting Epoch 1 ---
Step 1 (Epoch 1): Training Loss = 5.3535
{'loss': 5.3535, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.16}
Step 2: Loss = 5.3535, LR = 0.00e+00
Step 2 (Epoch 1): Training Loss = 4.2505
{'loss': 4.2505, 'grad_norm': 7.735963344573975, 'learning_rate': 2e-05, 'epoch': 0.32}
Step 3: Loss = 4.2505, LR = 2.00e-05
Step 3 (Epoch 1): Training Loss = 3.6526
{'loss': 3.6526, 'grad_norm': 4.974039554595947, 'learning_rate': 4e-05, 'epoch': 0.48}
Step 4: Loss = 3.6526, LR = 4.00e-05
Step 4 (Epoch 1): Training Loss = 3.4726
{'loss': 3.4726, 'grad_norm': 5.745538711547852, 'learning_rate': 6e-05, 'epoch': 0.64}
Step 5: Loss = 3.4726, LR = 6.00e-05
Step 5 (Epoch 1): Training Loss = 3.2152
{'loss': 3.2152, 'grad_norm': 6.539067268371582, 'learning_rate': 8e-05, 'epoch': 0.8}
Step 6: Loss = 3.2152, LR = 8.00e-05
Step 6 (Epoch 1): Training Loss = 2.5374
{'loss': 2.5374, 'grad_norm': 4.987270832061768, 'learning_rate': 0.0001, 'epoch': 0.96}
Step 7: Loss = 2.5374, LR = 1.00e-04
Step 7 (Epoch 1): Training Loss = 2.2453
{'loss': 2.2453, 'grad_norm': 2.866506338119507, 'learning_rate': 0.00012, 'epoch': 1.0}

--- Starting Epoch 2 ---
Step 8: Loss = 2.2453, LR = 1.20e-04
Step 8 (Epoch 2): Training Loss = 1.7428
{'loss': 1.7428, 'grad_norm': 0.9811012148857117, 'learning_rate': 0.00014000000000000001, 'epoch': 1.16}
Step 9: Loss = 1.7428, LR = 1.40e-04
Step 9 (Epoch 2): Training Loss = 1.8385
{'loss': 1.8385, 'grad_norm': 0.89522784948349, 'learning_rate': 0.00016, 'epoch': 1.32}
Step 10: Loss = 1.8385, LR = 1.60e-04
Step 10 (Epoch 2): Training Loss = 1.8984
{'loss': 1.8984, 'grad_norm': 0.9364137053489685, 'learning_rate': 0.00017999999999999998, 'epoch': 1.48}
Step 11: Loss = 1.8984, LR = 1.80e-04
Step 11 (Epoch 2): Training Loss = 1.7451
{'loss': 1.7451, 'grad_norm': 0.7941195964813232, 'learning_rate': 0.0002, 'epoch': 1.64}
Step 12: Loss = 1.7451, LR = 2.00e-04
Step 12 (Epoch 2): Training Loss = 1.7742
{'loss': 1.7742, 'grad_norm': 0.81709885597229, 'learning_rate': 0.00022, 'epoch': 1.8}
Step 13: Loss = 1.7742, LR = 2.20e-04
Step 13 (Epoch 2): Training Loss = 1.5292
{'loss': 1.5292, 'grad_norm': 0.7096231579780579, 'learning_rate': 0.00024, 'epoch': 1.96}
Step 14: Loss = 1.5292, LR = 2.40e-04
Step 14 (Epoch 2): Training Loss = 1.6310
{'loss': 1.631, 'grad_norm': 1.0477290153503418, 'learning_rate': 0.00026000000000000003, 'epoch': 2.0}

--- Starting Epoch 3 ---
Step 15: Loss = 1.6310, LR = 2.60e-04
Step 15 (Epoch 3): Training Loss = 1.4305
{'loss': 1.4305, 'grad_norm': 0.7642627358436584, 'learning_rate': 0.00028000000000000003, 'epoch': 2.16}
Step 16: Loss = 1.4305, LR = 2.80e-04
Step 16 (Epoch 3): Training Loss = 1.3618
{'loss': 1.3618, 'grad_norm': 0.5764961242675781, 'learning_rate': 0.0003, 'epoch': 2.32}
Step 17: Loss = 1.3618, LR = 3.00e-04
Step 17 (Epoch 3): Training Loss = 1.2327
{'loss': 1.2327, 'grad_norm': 0.4956953823566437, 'learning_rate': 0.00032, 'epoch': 2.48}
Step 18: Loss = 1.2327, LR = 3.20e-04
Step 18 (Epoch 3): Training Loss = 1.1823
{'loss': 1.1823, 'grad_norm': 0.6192808747291565, 'learning_rate': 0.00034, 'epoch': 2.64}
Step 19: Loss = 1.1823, LR = 3.40e-04
Step 19 (Epoch 3): Training Loss = 1.1660
{'loss': 1.166, 'grad_norm': 0.6695284843444824, 'learning_rate': 0.00035999999999999997, 'epoch': 2.8}
Step 20: Loss = 1.1660, LR = 3.60e-04
Step 20 (Epoch 3): Training Loss = 0.8642
{'loss': 0.8642, 'grad_norm': 0.39809128642082214, 'learning_rate': 0.00038, 'epoch': 2.96}
Step 21: Loss = 0.8642, LR = 3.80e-04
Step 21 (Epoch 3): Training Loss = 0.8918
{'loss': 0.8918, 'grad_norm': 0.43845513463020325, 'learning_rate': 0.0004, 'epoch': 3.0}

--- Starting Epoch 4 ---
Step 22: Loss = 0.8918, LR = 4.00e-04
Step 22 (Epoch 4): Training Loss = 1.0430
{'loss': 1.043, 'grad_norm': 0.3547460734844208, 'learning_rate': 0.00042, 'epoch': 3.16}
Step 23: Loss = 1.0430, LR = 4.20e-04
Step 23 (Epoch 4): Training Loss = 0.9924
{'loss': 0.9924, 'grad_norm': 0.42452237010002136, 'learning_rate': 0.00044, 'epoch': 3.32}
Step 24: Loss = 0.9924, LR = 4.40e-04
Step 24 (Epoch 4): Training Loss = 0.8022
{'loss': 0.8022, 'grad_norm': 0.24461165070533752, 'learning_rate': 0.00046, 'epoch': 3.48}
Step 25: Loss = 0.8022, LR = 4.60e-04
Step 25 (Epoch 4): Training Loss = 0.9458
{'loss': 0.9458, 'grad_norm': 0.37402451038360596, 'learning_rate': 0.00048, 'epoch': 3.64}
Step 26: Loss = 0.9458, LR = 4.80e-04
Step 26 (Epoch 4): Training Loss = 0.8829
{'loss': 0.8829, 'grad_norm': 0.33052706718444824, 'learning_rate': 0.0005, 'epoch': 3.8}
Step 27: Loss = 0.8829, LR = 5.00e-04
Step 27 (Epoch 4): Training Loss = 0.9198
{'loss': 0.9198, 'grad_norm': 0.32365885376930237, 'learning_rate': 0.0005200000000000001, 'epoch': 3.96}
Step 28: Loss = 0.9198, LR = 5.20e-04
Step 28 (Epoch 4): Training Loss = 0.9737
{'loss': 0.9737, 'grad_norm': 0.6303682327270508, 'learning_rate': 0.00054, 'epoch': 4.0}

--- Starting Epoch 5 ---
Step 29: Loss = 0.9737, LR = 5.40e-04
Step 29 (Epoch 5): Training Loss = 0.7614
{'loss': 0.7614, 'grad_norm': 0.38470253348350525, 'learning_rate': 0.0005600000000000001, 'epoch': 4.16}
Step 30: Loss = 0.7614, LR = 5.60e-04
Step 30 (Epoch 5): Training Loss = 0.7914
{'loss': 0.7914, 'grad_norm': 0.3364809453487396, 'learning_rate': 0.00058, 'epoch': 4.32}
Step 31: Loss = 0.7914, LR = 5.80e-04
Step 31 (Epoch 5): Training Loss = 0.8306
{'loss': 0.8306, 'grad_norm': 0.3847704231739044, 'learning_rate': 0.0006, 'epoch': 4.48}
Step 32: Loss = 0.8306, LR = 6.00e-04
Step 32 (Epoch 5): Training Loss = 0.6442
{'loss': 0.6442, 'grad_norm': 0.400673508644104, 'learning_rate': 0.00062, 'epoch': 4.64}
Step 33: Loss = 0.6442, LR = 6.20e-04
Step 33 (Epoch 5): Training Loss = 0.5848
{'loss': 0.5848, 'grad_norm': 0.34971997141838074, 'learning_rate': 0.00064, 'epoch': 4.8}
Step 34: Loss = 0.5848, LR = 6.40e-04
Step 34 (Epoch 5): Training Loss = 0.7507
{'loss': 0.7507, 'grad_norm': 0.4501504898071289, 'learning_rate': 0.00066, 'epoch': 4.96}
Step 35: Loss = 0.7507, LR = 6.60e-04
Step 35 (Epoch 5): Training Loss = 0.7580
{'loss': 0.758, 'grad_norm': 0.8585777282714844, 'learning_rate': 0.00068, 'epoch': 5.0}

--- Starting Epoch 6 ---
Step 36: Loss = 0.7580, LR = 6.80e-04
Step 36 (Epoch 6): Training Loss = 0.6324
{'loss': 0.6324, 'grad_norm': 0.41974085569381714, 'learning_rate': 0.0007, 'epoch': 5.16}
Step 37: Loss = 0.6324, LR = 7.00e-04
Step 37 (Epoch 6): Training Loss = 0.5276
{'loss': 0.5276, 'grad_norm': 0.4553542137145996, 'learning_rate': 0.0007199999999999999, 'epoch': 5.32}
Step 38: Loss = 0.5276, LR = 7.20e-04
Step 38 (Epoch 6): Training Loss = 0.5567
{'loss': 0.5567, 'grad_norm': 0.5159577131271362, 'learning_rate': 0.00074, 'epoch': 5.48}
Step 39: Loss = 0.5567, LR = 7.40e-04
Step 39 (Epoch 6): Training Loss = 0.4878
{'loss': 0.4878, 'grad_norm': 0.5056953430175781, 'learning_rate': 0.00076, 'epoch': 5.64}
Step 40: Loss = 0.4878, LR = 7.60e-04
Step 40 (Epoch 6): Training Loss = 0.5618
{'loss': 0.5618, 'grad_norm': 0.5847556591033936, 'learning_rate': 0.0007800000000000001, 'epoch': 5.8}
Step 41: Loss = 0.5618, LR = 7.80e-04
Step 41 (Epoch 6): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008, 'epoch': 5.96}
Step 42: Loss = 0.0000, LR = 8.00e-04
Step 42 (Epoch 6): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00082, 'epoch': 6.0}

--- Starting Epoch 7 ---
Step 43: Loss = 0.0000, LR = 8.20e-04
Step 43 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00084, 'epoch': 6.16}
Step 44: Loss = 0.0000, LR = 8.40e-04
Step 44 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00086, 'epoch': 6.32}
Step 45: Loss = 0.0000, LR = 8.60e-04
Step 45 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00088, 'epoch': 6.48}
Step 46: Loss = 0.0000, LR = 8.80e-04
Step 46 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009000000000000001, 'epoch': 6.64}
Step 47: Loss = 0.0000, LR = 9.00e-04
Step 47 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00092, 'epoch': 6.8}
Step 48: Loss = 0.0000, LR = 9.20e-04
Step 48 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00094, 'epoch': 6.96}
Step 49: Loss = 0.0000, LR = 9.40e-04
Step 49 (Epoch 7): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00096, 'epoch': 7.0}

--- Starting Epoch 8 ---
Step 50: Loss = 0.0000, LR = 9.60e-04
Step 50 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00098, 'epoch': 7.16}
Step 51: Loss = 0.0000, LR = 9.80e-04
Step 51 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.001, 'epoch': 7.32}
Step 52: Loss = 0.0000, LR = 1.00e-03
Step 52 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.000988888888888889, 'epoch': 7.48}
Step 53: Loss = 0.0000, LR = 9.89e-04
Step 53 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009777777777777777, 'epoch': 7.64}
Step 54: Loss = 0.0000, LR = 9.78e-04
Step 54 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009666666666666667, 'epoch': 7.8}
Step 55: Loss = 0.0000, LR = 9.67e-04
Step 55 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009555555555555556, 'epoch': 7.96}
Step 56: Loss = 0.0000, LR = 9.56e-04
Step 56 (Epoch 8): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009444444444444445, 'epoch': 8.0}

--- Starting Epoch 9 ---
Step 57: Loss = 0.0000, LR = 9.44e-04
Step 57 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009333333333333333, 'epoch': 8.16}
Step 58: Loss = 0.0000, LR = 9.33e-04
Step 58 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009222222222222223, 'epoch': 8.32}
Step 59: Loss = 0.0000, LR = 9.22e-04
Step 59 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009111111111111111, 'epoch': 8.48}
Step 60: Loss = 0.0000, LR = 9.11e-04
Step 60 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0009000000000000001, 'epoch': 8.64}
Step 61: Loss = 0.0000, LR = 9.00e-04
Step 61 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008888888888888888, 'epoch': 8.8}
Step 62: Loss = 0.0000, LR = 8.89e-04
Step 62 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008777777777777778, 'epoch': 8.96}
Step 63: Loss = 0.0000, LR = 8.78e-04
Step 63 (Epoch 9): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008666666666666667, 'epoch': 9.0}

--- Starting Epoch 10 ---
Step 64: Loss = 0.0000, LR = 8.67e-04
Step 64 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008555555555555556, 'epoch': 9.16}
Step 65: Loss = 0.0000, LR = 8.56e-04
Step 65 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008444444444444444, 'epoch': 9.32}
Step 66: Loss = 0.0000, LR = 8.44e-04
Step 66 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008333333333333334, 'epoch': 9.48}
Step 67: Loss = 0.0000, LR = 8.33e-04
Step 67 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008222222222222222, 'epoch': 9.64}
Step 68: Loss = 0.0000, LR = 8.22e-04
Step 68 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008111111111111111, 'epoch': 9.8}
Step 69: Loss = 0.0000, LR = 8.11e-04
Step 69 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0008, 'epoch': 9.96}
Step 70: Loss = 0.0000, LR = 8.00e-04
Step 70 (Epoch 10): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007888888888888889, 'epoch': 10.0}

--- Starting Epoch 11 ---
Step 71: Loss = 0.0000, LR = 7.89e-04
Step 71 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007777777777777778, 'epoch': 10.16}
Step 72: Loss = 0.0000, LR = 7.78e-04
Step 72 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007666666666666667, 'epoch': 10.32}
Step 73: Loss = 0.0000, LR = 7.67e-04
Step 73 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007555555555555555, 'epoch': 10.48}
Step 74: Loss = 0.0000, LR = 7.56e-04
Step 74 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007444444444444445, 'epoch': 10.64}
Step 75: Loss = 0.0000, LR = 7.44e-04
Step 75 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007333333333333333, 'epoch': 10.8}
Step 76: Loss = 0.0000, LR = 7.33e-04
Step 76 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007222222222222222, 'epoch': 10.96}
Step 77: Loss = 0.0000, LR = 7.22e-04
Step 77 (Epoch 11): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007111111111111111, 'epoch': 11.0}

--- Starting Epoch 12 ---
Step 78: Loss = 0.0000, LR = 7.11e-04
Step 78 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0007, 'epoch': 11.16}
Step 79: Loss = 0.0000, LR = 7.00e-04
Step 79 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.000688888888888889, 'epoch': 11.32}
Step 80: Loss = 0.0000, LR = 6.89e-04
Step 80 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006777777777777778, 'epoch': 11.48}
Step 81: Loss = 0.0000, LR = 6.78e-04
Step 81 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006666666666666666, 'epoch': 11.64}
Step 82: Loss = 0.0000, LR = 6.67e-04
Step 82 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006555555555555556, 'epoch': 11.8}
Step 83: Loss = 0.0000, LR = 6.56e-04
Step 83 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006444444444444444, 'epoch': 11.96}
Step 84: Loss = 0.0000, LR = 6.44e-04
Step 84 (Epoch 12): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006333333333333333, 'epoch': 12.0}

--- Starting Epoch 13 ---
Step 85: Loss = 0.0000, LR = 6.33e-04
Step 85 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006222222222222223, 'epoch': 12.16}
Step 86: Loss = 0.0000, LR = 6.22e-04
Step 86 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006111111111111112, 'epoch': 12.32}
Step 87: Loss = 0.0000, LR = 6.11e-04
Step 87 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0006, 'epoch': 12.48}
Step 88: Loss = 0.0000, LR = 6.00e-04
Step 88 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005888888888888889, 'epoch': 12.64}
Step 89: Loss = 0.0000, LR = 5.89e-04
Step 89 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005777777777777778, 'epoch': 12.8}
Step 90: Loss = 0.0000, LR = 5.78e-04
Step 90 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005666666666666667, 'epoch': 12.96}
Step 91: Loss = 0.0000, LR = 5.67e-04
Step 91 (Epoch 13): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005555555555555556, 'epoch': 13.0}

--- Starting Epoch 14 ---
Step 92: Loss = 0.0000, LR = 5.56e-04
Step 92 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005444444444444444, 'epoch': 13.16}
Step 93: Loss = 0.0000, LR = 5.44e-04
Step 93 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005333333333333334, 'epoch': 13.32}
Step 94: Loss = 0.0000, LR = 5.33e-04
Step 94 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005222222222222223, 'epoch': 13.48}
Step 95: Loss = 0.0000, LR = 5.22e-04
Step 95 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005111111111111111, 'epoch': 13.64}
Step 96: Loss = 0.0000, LR = 5.11e-04
Step 96 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0005, 'epoch': 13.8}
Step 97: Loss = 0.0000, LR = 5.00e-04
Step 97 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004888888888888889, 'epoch': 13.96}
Step 98: Loss = 0.0000, LR = 4.89e-04
Step 98 (Epoch 14): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004777777777777778, 'epoch': 14.0}

--- Starting Epoch 15 ---
Step 99: Loss = 0.0000, LR = 4.78e-04
Step 99 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00046666666666666666, 'epoch': 14.16}
Step 100: Loss = 0.0000, LR = 4.67e-04
Step 100 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00045555555555555556, 'epoch': 14.32}
Step 101: Loss = 0.0000, LR = 4.56e-04
Step 101 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004444444444444444, 'epoch': 14.48}
Step 102: Loss = 0.0000, LR = 4.44e-04
Step 102 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00043333333333333337, 'epoch': 14.64}
Step 103: Loss = 0.0000, LR = 4.33e-04
Step 103 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004222222222222222, 'epoch': 14.8}
Step 104: Loss = 0.0000, LR = 4.22e-04
Step 104 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004111111111111111, 'epoch': 14.96}
Step 105: Loss = 0.0000, LR = 4.11e-04
Step 105 (Epoch 15): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0004, 'epoch': 15.0}

--- Starting Epoch 16 ---
Step 106: Loss = 0.0000, LR = 4.00e-04
Step 106 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003888888888888889, 'epoch': 15.16}
Step 107: Loss = 0.0000, LR = 3.89e-04
Step 107 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00037777777777777777, 'epoch': 15.32}
Step 108: Loss = 0.0000, LR = 3.78e-04
Step 108 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00036666666666666667, 'epoch': 15.48}
Step 109: Loss = 0.0000, LR = 3.67e-04
Step 109 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00035555555555555557, 'epoch': 15.64}
Step 110: Loss = 0.0000, LR = 3.56e-04
Step 110 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003444444444444445, 'epoch': 15.8}
Step 111: Loss = 0.0000, LR = 3.44e-04
Step 111 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003333333333333333, 'epoch': 15.96}
Step 112: Loss = 0.0000, LR = 3.33e-04
Step 112 (Epoch 16): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003222222222222222, 'epoch': 16.0}

--- Starting Epoch 17 ---
Step 113: Loss = 0.0000, LR = 3.22e-04
Step 113 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003111111111111111, 'epoch': 16.16}
Step 114: Loss = 0.0000, LR = 3.11e-04
Step 114 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 16.32}
Step 115: Loss = 0.0000, LR = 3.00e-04
Step 115 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002888888888888889, 'epoch': 16.48}
Step 116: Loss = 0.0000, LR = 2.89e-04
Step 116 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002777777777777778, 'epoch': 16.64}
Step 117: Loss = 0.0000, LR = 2.78e-04
Step 117 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002666666666666667, 'epoch': 16.8}
Step 118: Loss = 0.0000, LR = 2.67e-04
Step 118 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00025555555555555553, 'epoch': 16.96}
Step 119: Loss = 0.0000, LR = 2.56e-04
Step 119 (Epoch 17): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00024444444444444443, 'epoch': 17.0}

--- Starting Epoch 18 ---
Step 120: Loss = 0.0000, LR = 2.44e-04
Step 120 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00023333333333333333, 'epoch': 17.16}
Step 121: Loss = 0.0000, LR = 2.33e-04
Step 121 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002222222222222222, 'epoch': 17.32}
Step 122: Loss = 0.0000, LR = 2.22e-04
Step 122 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002111111111111111, 'epoch': 17.48}
Step 123: Loss = 0.0000, LR = 2.11e-04
Step 123 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002, 'epoch': 17.64}
Step 124: Loss = 0.0000, LR = 2.00e-04
Step 124 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00018888888888888888, 'epoch': 17.8}
Step 125: Loss = 0.0000, LR = 1.89e-04
Step 125 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00017777777777777779, 'epoch': 17.96}
Step 126: Loss = 0.0000, LR = 1.78e-04
Step 126 (Epoch 18): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00016666666666666666, 'epoch': 18.0}

--- Starting Epoch 19 ---
Step 127: Loss = 0.0000, LR = 1.67e-04
Step 127 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00015555555555555556, 'epoch': 18.16}
Step 128: Loss = 0.0000, LR = 1.56e-04
Step 128 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00014444444444444444, 'epoch': 18.32}
Step 129: Loss = 0.0000, LR = 1.44e-04
Step 129 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00013333333333333334, 'epoch': 18.48}
Step 130: Loss = 0.0000, LR = 1.33e-04
Step 130 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00012222222222222221, 'epoch': 18.64}
Step 131: Loss = 0.0000, LR = 1.22e-04
Step 131 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0001111111111111111, 'epoch': 18.8}
Step 132: Loss = 0.0000, LR = 1.11e-04
Step 132 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0001, 'epoch': 18.96}
Step 133: Loss = 0.0000, LR = 1.00e-04
Step 133 (Epoch 19): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.888888888888889e-05, 'epoch': 19.0}

--- Starting Epoch 20 ---
Step 134: Loss = 0.0000, LR = 8.89e-05
Step 134 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.777777777777778e-05, 'epoch': 19.16}
Step 135: Loss = 0.0000, LR = 7.78e-05
Step 135 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.666666666666667e-05, 'epoch': 19.32}
Step 136: Loss = 0.0000, LR = 6.67e-05
Step 136 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.555555555555555e-05, 'epoch': 19.48}
Step 137: Loss = 0.0000, LR = 5.56e-05
Step 137 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.4444444444444447e-05, 'epoch': 19.64}
Step 138: Loss = 0.0000, LR = 4.44e-05
Step 138 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.3333333333333335e-05, 'epoch': 19.8}
Step 139: Loss = 0.0000, LR = 3.33e-05
Step 139 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.2222222222222223e-05, 'epoch': 19.96}
Step 140: Loss = 0.0000, LR = 2.22e-05
Step 140 (Epoch 20): Training Loss = 0.0000
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.1111111111111112e-05, 'epoch': 20.0}
{'train_runtime': 1255.1384, 'train_samples_per_second': 1.593, 'train_steps_per_second': 0.112, 'train_loss': 0.42473545329911366, 'epoch': 20.0}
==================================================
Saving adapter...
Training complete! Adapter saved to /workspace/NLP_Project/adapters/ep20_bs2_lr1e-3_r8_layers10_genQA
Loading test data...
Successfully loaded 100 items from JSON file
Evaluating on 100 samples
Loading model...
Generating predictions...

--- Sample 1 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what country is Normandy located?
Expected: France
Predicted: France

--- Sample 2 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When were the Normans in Normandy?
Expected: 10th and 11th centuries
Predicted: 911–944

--- Sample 3 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: From which countries did the Norse originate?
Expected: Denmark, Iceland and Norway
Predicted: Denmark, Iceland, and Norway

--- Sample 4 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the Norse leader?
Expected: Rollo
Predicted: Rollo

--- Sample 5 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What century did the Normans first gain their separate identity?
Expected: 10th century
Predicted: 11th century

--- Sample 6 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the duke in the battle of Hastings?
Expected: William the Conqueror
Predicted: Duke of Normandy

--- Sample 7 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruled the duchy of Normandy
Expected: Richard I
Predicted: Rollo

--- Sample 8 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What religion were the Normans
Expected: Catholic
Predicted: Catholic

--- Sample 9 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the original meaning of the word Norman?
Expected: Viking
Predicted: Norseman

--- Sample 10 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Latin version of the word Norman first recorded?
Expected: 9th century
Predicted: 1052

--- Sample 11 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Duchy of Normandy founded?
Expected: 911
Predicted: 911

--- Sample 12 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Rollo sign the treaty of Saint-Clair-sur-Epte with?
Expected: King Charles III
Predicted: King Charles III of West Francia

--- Sample 13 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What river originally bounded the Duchy
Expected: Seine
Predicted: Seine

--- Sample 14 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who upon arriving gave the original viking settlers a common identity?
Expected: Rollo
Predicted: Duke Richard II

--- Sample 15 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the Norman religion?
Expected: Catholicism
Predicted: Christianity

--- Sample 16 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What part of France were the Normans located?
Expected: north
Predicted: Normandy

--- Sample 17 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was one of the Norman's major exports?
Expected: fighting horsemen
Predicted: wool

--- Sample 18 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the Normans' main enemy in Italy, the Byzantine Empire and Armenia?
Expected: Seljuk Turks
Predicted: Papal states

--- Sample 19 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Herve serve as a Byzantine general?
Expected: 1050s
Predicted: 1057

--- Sample 20 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Robert Crispin go up against the Turks?
Expected: 1060s
Predicted: 1064

--- Sample 21 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruined Roussel de Bailleul's plans for an independent state?
Expected: Alexius Komnenos
Predicted: Richard the Lion-Heart

--- Sample 22 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of the Norman castle?
Expected: Afranji
Predicted: Roumois

--- Sample 23 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the leader when the Franks entered the Euphrates valley?
Expected: Oursel
Predicted: Rollo

--- Sample 24 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did the Normans team up with in Anatolia?
Expected: Turkish forces
Predicted: Turkish forces

--- Sample 25 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What were the origins of the Raouliii family?
Expected: Norman mercenary
Predicted: Normans

--- Sample 26 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of the count of Apulia 
Expected: Robert Guiscard
Predicted: Richard de Camville

--- Sample 27 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Dyrrachium  fall to the Normans?
Expected: 1082
Predicted: 1185

--- Sample 28 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How many men were in Robert's army?
Expected: 30,000
Predicted: 10,000

--- Sample 29 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did the Normans and Byzantines sign the peace treaty?
Expected: Deabolis
Predicted: Trebizond

--- Sample 30 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Robert's son?
Expected: Bohemond
Predicted: Edmund

--- Sample 31 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What river was Petrela located by?
Expected: Deabolis
Predicted: Tisza

--- Sample 32 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the Normans attack Dyrrachium?
Expected: 1185
Predicted: 1081

--- Sample 33 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the naval base called?
Expected: Dyrrachium
Predicted: Porto Cervo

--- Sample 34 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where was Dyrrachium located?
Expected: the Adriatic
Predicted: Greece

--- Sample 35 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Emma Marry?
Expected: King Ethelred II
Predicted: Duke Richard II of Normandy

--- Sample 36 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Emma's brother?
Expected: Duke Richard II
Predicted: Duke Richard II

--- Sample 37 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: To where did Ethelred flee?
Expected: Normandy
Predicted: Dalmatia

--- Sample 38 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who kicked Ethelred out?
Expected: Sweyn Forkbeard
Predicted: Duke Richard of Normandy

--- Sample 39 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Edward the Confessor's half-brother?
Expected: Harthacnut
Predicted: Harthacnut

--- Sample 40 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Edward return?
Expected: 1041
Predicted: 1041

--- Sample 41 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Edward make archbishop of Canterbury?
Expected: Robert of Jumièges
Predicted: Robert of Jumièges

--- Sample 42 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did Harold II die?
Expected: Battle of Hastings
Predicted: At the Battle of Hastings

--- Sample 43 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who killed Harold II? 
Expected: William II
Predicted: William the Conqueror

--- Sample 44 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Battle of Hastings?
Expected: 1066
Predicted: 1066

--- Sample 45 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the ruling class ahead of the Normans?
Expected: Anglo-Saxons
Predicted: Anglo-Saxons

--- Sample 46 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the Anglo-Norman language's final form?
Expected: Modern English
Predicted: Middle English

--- Sample 47 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what year did the Norman's invade at Bannow Bay?
Expected: 1169
Predicted: 1169

--- Sample 48 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What country did the Normans invade in 1169?
Expected: Ireland
Predicted: Ireland

--- Sample 49 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What culture did the Normans combine with in Ireland?
Expected: Irish
Predicted: Irish

--- Sample 50 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Margaret's brother?
Expected: Edgar
Predicted: Edmund

--- Sample 51 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Margaret's husband?
Expected: King Malcolm III of Scotland
Predicted: Duke of Normandy

--- Sample 52 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was Scotland invaded by William?
Expected: 1072
Predicted: 1072

--- Sample 53 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the hostage?
Expected: Duncan
Predicted: Edith

--- Sample 54 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Alexander I marry?
Expected: Sybilla of Normandy
Predicted: Catherine of Braganza

--- Sample 55 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What culture's arrival in Scotland is know as the "Davidian Revolution"?
Expected: Norman
Predicted: Normans

--- Sample 56 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where was Ralph earl of?
Expected: Hereford
Predicted: Wessex

--- Sample 57 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Ralph in charge of being at war with?
Expected: the Welsh
Predicted: the Normans

--- Sample 58 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who made Ralph earl?
Expected: Edward the Confessor
Predicted: Edward the Confessor

--- Sample 59 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What country was under the control of Norman barons?
Expected: Wales
Predicted: England

--- Sample 60 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What year did Roger de Tosny fail to accomplish what he set out to do?
Expected: 1018
Predicted: 1064

--- Sample 61 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was in charge of the papal army in the War of Barbastro?
Expected: William of Montreuil
Predicted: Richard de Camville

--- Sample 62 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the Siege of Antioch take place?
Expected: 1097
Predicted: 1097

--- Sample 63 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of Bohemond's nephew?
Expected: Tancred
Predicted: Richard

--- Sample 64 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What major conquest did Tancred play a roll in?
Expected: Jerusalem
Predicted: Conquest of Cyprus

--- Sample 65 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How long did Western Europe control Cyprus?
Expected: 380 years
Predicted: 380 years

--- Sample 66 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What ruined Richard's plans to reach Acre?
Expected: a storm
Predicted: The storm

--- Sample 67 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Richard's fiancee?
Expected: Berengaria
Predicted: Berengaria

--- Sample 68 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What year did the storm hit Richard's fleet?
Expected: 1191
Predicted: 1191

--- Sample 69 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruled Cyprus in 1191?
Expected: Isaac Komnenos
Predicted: Richard the Lion-Heart

--- Sample 70 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Guy's Rival?
Expected: Conrad of Montferrat
Predicted: Bohemond

--- Sample 71 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What were Isaac's chains made out of?
Expected: silver
Predicted: iron

--- Sample 72 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who led Richard's troops when Cyprus was conquered?
Expected: Guy de Lusignan
Predicted: Guy de Lusignan

--- Sample 73 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What continent are the Canarian Islands off the coast of?
Expected: Africa
Predicted: Africa

--- Sample 74 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who became the King of the Canary Islands?
Expected: Bethencourt
Predicted: Henry III

--- Sample 75 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who bought the rights?
Expected: Enrique Pérez de Guzmán
Predicted: Richard the Lion-Heart

--- Sample 76 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who sold the rights?
Expected: Maciot de Bethencourt
Predicted: Richard the Lion-Heart

--- Sample 77 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where are Jersey and Guernsey
Expected: Channel Islands
Predicted: Channel Islands

--- Sample 78 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How many customaries does Norman customary law have?
Expected: two
Predicted: two

--- Sample 79 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the Norman architecture idiom?
Expected: Romanesque
Predicted: Norman architecture

--- Sample 80 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What kind of arches does Norman architecture have?
Expected: rounded
Predicted: rounded

--- Sample 81 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What architecture type came after Norman in England?
Expected: Early Gothic
Predicted: Gothic

--- Sample 82 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What architecture type came before Norman in England?
Expected: Anglo-Saxon
Predicted: Anglo-Saxon

--- Sample 83 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What place had the Norman Arab architectural style?
Expected: Sicily
Predicted: Jerusalem

--- Sample 84 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the church reform begin?
Expected: early 11th century
Predicted: 1050

--- Sample 85 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who used the church to unify themselves?
Expected: dukes
Predicted: Normans

--- Sample 86 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When were the French wars of religion?
Expected: 16th century
Predicted: 1562–1598

--- Sample 87 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What kind of needlework was used in the creation of the Bayeux Tapestry?
Expected: embroidery
Predicted: Embroidery

--- Sample 88 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is Norman art's most well known piece?
Expected: Bayeux Tapestry
Predicted: Bayeux Tapestry

--- Sample 89 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who commissioned the Tapestry?
Expected: Odo
Predicted: Odo

--- Sample 90 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the most important type of Norman art preserved in churches?
Expected: mosaics
Predicted: sculpture

--- Sample 91 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what century did important classical music developments occur in Normandy?
Expected: 11th
Predicted: 11th

--- Sample 92 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who were the two abbots at Fécamp Abbey?
Expected: William of Volpiano and John of Ravenna
Predicted: Robert de Grantmesnil and Richard de Camville

--- Sample 93 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did the monks flee to?
Expected: southern Italy
Predicted: France

--- Sample 94 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What monastery did the Saint-Evroul monks establish in Italy?
Expected: Latin monastery at Sant'Eufemia.
Predicted: San Clemente

--- Sample 95 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who patronized the monks in Italy? 
Expected: Robert Guiscard
Predicted: Rome

--- Sample 96 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What tradition were the Saint-Evroul monks known for?
Expected: singing
Predicted: Norman customary law

--- Sample 97 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?
Expected: Computational complexity theory
Predicted: Computational complexity theory

--- Sample 98 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: By what main attribute are computational problems classified utilizing computational complexity theory? 
Expected: inherent difficulty
Predicted: difficulty

--- Sample 99 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the term for a task that generally lends itself to being solved by a computer?
Expected: computational problems
Predicted: computational problem

--- Sample 100 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What measure of a computational problem broadly defines the inherent difficulty of the solution?
Expected: if its solution requires significant resources
Predicted: input size
Evaluating...

=== Benchmark Results ===
Exact Accuracy: 0.320
Partial Accuracy: 0.490
Exact Matches: 32/100
Partial Matches: 17/100

Detailed results saved to benchmark_results.json
Starting LoRA training with RTX 3090 optimized settings...
Epochs: 20, Batch size: 2, Learning rate: 0.001
Command: python train_lora_optimized.py --model_name Qwen/Qwen3-8B --epochs 20 --batch_size 2 --learning_rate 0.001 --adapter_r 8 --adapter_layers 10 --output_dir /workspace/NLP_Project/adapters/ep20_bs2_lr1e-3_r8_layers10_genQA --use_generated_qa --generated_qa_dir outputs/qa_1_2048_fixed

Training completed successfully!
