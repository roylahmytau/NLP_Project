Loading data...
Successfully loaded 100 items from JSON file
Loaded 100 examples
Creating model...
Trainable parameters: 21,823,488
Total parameters: 4,739,675,136
Trainable %: 0.46%
Starting training...
Total training steps: 120
==================================================

--- Starting Epoch 1 ---
Step 1 (Epoch 1): Training Loss = 4.4684
{'loss': 4.4684, 'grad_norm': 3.970175266265869, 'learning_rate': 0.0, 'epoch': 0.16}
Step 2: Loss = 4.4684, LR = 0.00e+00
Step 2 (Epoch 1): Training Loss = 3.9402
{'loss': 3.9402, 'grad_norm': 3.3908376693725586, 'learning_rate': 2e-05, 'epoch': 0.32}
Step 3: Loss = 3.9402, LR = 2.00e-05
Step 3 (Epoch 1): Training Loss = 4.2208
{'loss': 4.2208, 'grad_norm': 3.8392488956451416, 'learning_rate': 4e-05, 'epoch': 0.48}
Step 4: Loss = 4.2208, LR = 4.00e-05
Step 4 (Epoch 1): Training Loss = 4.0000
{'loss': 4.0, 'grad_norm': 3.483409881591797, 'learning_rate': 6e-05, 'epoch': 0.64}
Step 5: Loss = 4.0000, LR = 6.00e-05
Step 5 (Epoch 1): Training Loss = 3.7132
{'loss': 3.7132, 'grad_norm': 3.9278457164764404, 'learning_rate': 8e-05, 'epoch': 0.8}
Step 6: Loss = 3.7132, LR = 8.00e-05
Step 6 (Epoch 1): Training Loss = 3.3768
{'loss': 3.3768, 'grad_norm': 2.9869332313537598, 'learning_rate': 0.0001, 'epoch': 0.96}
Step 7: Loss = 3.3768, LR = 1.00e-04
Step 7 (Epoch 1): Training Loss = 3.0417
{'loss': 3.0417, 'grad_norm': 4.84160852432251, 'learning_rate': 0.00012, 'epoch': 1.0}

--- Starting Epoch 2 ---
Step 8: Loss = 3.0417, LR = 1.20e-04
Step 8 (Epoch 2): Training Loss = 2.7322
{'loss': 2.7322, 'grad_norm': 3.2471396923065186, 'learning_rate': 0.00014000000000000001, 'epoch': 1.16}
Step 9: Loss = 2.7322, LR = 1.40e-04
Step 9 (Epoch 2): Training Loss = 2.4132
{'loss': 2.4132, 'grad_norm': 3.5529282093048096, 'learning_rate': 0.00016, 'epoch': 1.32}
Step 10: Loss = 2.4132, LR = 1.60e-04
Step 10 (Epoch 2): Training Loss = 2.0750
{'loss': 2.075, 'grad_norm': 2.3272628784179688, 'learning_rate': 0.00017999999999999998, 'epoch': 1.48}
Step 11: Loss = 2.0750, LR = 1.80e-04
Step 11 (Epoch 2): Training Loss = 1.5796
{'loss': 1.5796, 'grad_norm': 2.3102097511291504, 'learning_rate': 0.0002, 'epoch': 1.64}
Step 12: Loss = 1.5796, LR = 2.00e-04
Step 12 (Epoch 2): Training Loss = 1.4144
{'loss': 1.4144, 'grad_norm': 2.772033452987671, 'learning_rate': 0.00022, 'epoch': 1.8}
Step 13: Loss = 1.4144, LR = 2.20e-04
Step 13 (Epoch 2): Training Loss = 1.1706
{'loss': 1.1706, 'grad_norm': 2.317063331604004, 'learning_rate': 0.00024, 'epoch': 1.96}
Step 14: Loss = 1.1706, LR = 2.40e-04
Step 14 (Epoch 2): Training Loss = 0.9726
{'loss': 0.9726, 'grad_norm': 2.3970775604248047, 'learning_rate': 0.00026000000000000003, 'epoch': 2.0}

--- Starting Epoch 3 ---
Step 15: Loss = 0.9726, LR = 2.60e-04
Step 15 (Epoch 3): Training Loss = 0.8590
{'loss': 0.859, 'grad_norm': 2.057856798171997, 'learning_rate': 0.00028000000000000003, 'epoch': 2.16}
Step 16: Loss = 0.8590, LR = 2.80e-04
Step 16 (Epoch 3): Training Loss = 0.8214
{'loss': 0.8214, 'grad_norm': 1.2558388710021973, 'learning_rate': 0.0003, 'epoch': 2.32}
Step 17: Loss = 0.8214, LR = 3.00e-04
Step 17 (Epoch 3): Training Loss = 0.7910
{'loss': 0.791, 'grad_norm': 1.2831494808197021, 'learning_rate': 0.00032, 'epoch': 2.48}
Step 18: Loss = 0.7910, LR = 3.20e-04
Step 18 (Epoch 3): Training Loss = 0.7421
{'loss': 0.7421, 'grad_norm': 1.0769531726837158, 'learning_rate': 0.00034, 'epoch': 2.64}
Step 19: Loss = 0.7421, LR = 3.40e-04
Step 19 (Epoch 3): Training Loss = 0.6906
{'loss': 0.6906, 'grad_norm': 0.8617405891418457, 'learning_rate': 0.00035999999999999997, 'epoch': 2.8}
Step 20: Loss = 0.6906, LR = 3.60e-04
Step 20 (Epoch 3): Training Loss = 0.6950
{'loss': 0.695, 'grad_norm': 0.7974444031715393, 'learning_rate': 0.00038, 'epoch': 2.96}
Step 21: Loss = 0.6950, LR = 3.80e-04
Step 21 (Epoch 3): Training Loss = 0.7459
{'loss': 0.7459, 'grad_norm': 1.2949587106704712, 'learning_rate': 0.0004, 'epoch': 3.0}

--- Starting Epoch 4 ---
Step 22: Loss = 0.7459, LR = 4.00e-04
Step 22 (Epoch 4): Training Loss = 0.5635
{'loss': 0.5635, 'grad_norm': 0.9028272032737732, 'learning_rate': 0.00042, 'epoch': 3.16}
Step 23: Loss = 0.5635, LR = 4.20e-04
Step 23 (Epoch 4): Training Loss = 0.5763
{'loss': 0.5763, 'grad_norm': 1.1672987937927246, 'learning_rate': 0.00044, 'epoch': 3.32}
Step 24: Loss = 0.5763, LR = 4.40e-04
Step 24 (Epoch 4): Training Loss = 0.5437
{'loss': 0.5437, 'grad_norm': 1.048935890197754, 'learning_rate': 0.00046, 'epoch': 3.48}
Step 25: Loss = 0.5437, LR = 4.60e-04
Step 25 (Epoch 4): Training Loss = 0.5575
{'loss': 0.5575, 'grad_norm': 1.0192691087722778, 'learning_rate': 0.00048, 'epoch': 3.64}
Step 26: Loss = 0.5575, LR = 4.80e-04
Step 26 (Epoch 4): Training Loss = 0.4488
{'loss': 0.4488, 'grad_norm': 0.7697628140449524, 'learning_rate': 0.0005, 'epoch': 3.8}
Step 27: Loss = 0.4488, LR = 5.00e-04
Step 27 (Epoch 4): Training Loss = 0.5189
{'loss': 0.5189, 'grad_norm': 0.8086584210395813, 'learning_rate': 0.0005200000000000001, 'epoch': 3.96}
Step 28: Loss = 0.5189, LR = 5.20e-04
Step 28 (Epoch 4): Training Loss = 0.4259
{'loss': 0.4259, 'grad_norm': 0.7991389632225037, 'learning_rate': 0.00054, 'epoch': 4.0}

--- Starting Epoch 5 ---
Step 29: Loss = 0.4259, LR = 5.40e-04
Step 29 (Epoch 5): Training Loss = 0.3920
{'loss': 0.392, 'grad_norm': 0.5195335149765015, 'learning_rate': 0.0005600000000000001, 'epoch': 4.16}
Step 30: Loss = 0.3920, LR = 5.60e-04
Step 30 (Epoch 5): Training Loss = 0.3675
{'loss': 0.3675, 'grad_norm': 0.4861971437931061, 'learning_rate': 0.00058, 'epoch': 4.32}
Step 31: Loss = 0.3675, LR = 5.80e-04
Step 31 (Epoch 5): Training Loss = 0.3573
{'loss': 0.3573, 'grad_norm': 0.43664517998695374, 'learning_rate': 0.0006, 'epoch': 4.48}
Step 32: Loss = 0.3573, LR = 6.00e-04
Step 32 (Epoch 5): Training Loss = 0.3341
{'loss': 0.3341, 'grad_norm': 0.4885837137699127, 'learning_rate': 0.00062, 'epoch': 4.64}
Step 33: Loss = 0.3341, LR = 6.20e-04
Step 33 (Epoch 5): Training Loss = 0.3231
{'loss': 0.3231, 'grad_norm': 0.42377394437789917, 'learning_rate': 0.00064, 'epoch': 4.8}
Step 34: Loss = 0.3231, LR = 6.40e-04
Step 34 (Epoch 5): Training Loss = 0.4353
{'loss': 0.4353, 'grad_norm': 0.5329509377479553, 'learning_rate': 0.00066, 'epoch': 4.96}
Step 35: Loss = 0.4353, LR = 6.60e-04
Step 35 (Epoch 5): Training Loss = 0.3772
{'loss': 0.3772, 'grad_norm': 1.0031299591064453, 'learning_rate': 0.00068, 'epoch': 5.0}

--- Starting Epoch 6 ---
Step 36: Loss = 0.3772, LR = 6.80e-04
Step 36 (Epoch 6): Training Loss = 0.2598
{'loss': 0.2598, 'grad_norm': 0.423580527305603, 'learning_rate': 0.0007, 'epoch': 5.16}
Step 37: Loss = 0.2598, LR = 7.00e-04
Step 37 (Epoch 6): Training Loss = 0.2460
{'loss': 0.246, 'grad_norm': 0.39907851815223694, 'learning_rate': 0.0007199999999999999, 'epoch': 5.32}
Step 38: Loss = 0.2460, LR = 7.20e-04
Step 38 (Epoch 6): Training Loss = 0.2835
{'loss': 0.2835, 'grad_norm': 0.5687183141708374, 'learning_rate': 0.00074, 'epoch': 5.48}
Step 39: Loss = 0.2835, LR = 7.40e-04
Step 39 (Epoch 6): Training Loss = 0.2657
{'loss': 0.2657, 'grad_norm': 1.3506817817687988, 'learning_rate': 0.00076, 'epoch': 5.64}
Step 40: Loss = 0.2657, LR = 7.60e-04
Step 40 (Epoch 6): Training Loss = 0.2819
{'loss': 0.2819, 'grad_norm': 0.6080132722854614, 'learning_rate': 0.0007800000000000001, 'epoch': 5.8}
Step 41: Loss = 0.2819, LR = 7.80e-04
Step 41 (Epoch 6): Training Loss = 0.3444
{'loss': 0.3444, 'grad_norm': 2.6445655822753906, 'learning_rate': 0.0008, 'epoch': 5.96}
Step 42: Loss = 0.3444, LR = 8.00e-04
Step 42 (Epoch 6): Training Loss = 0.2543
{'loss': 0.2543, 'grad_norm': 1.0199946165084839, 'learning_rate': 0.00082, 'epoch': 6.0}

--- Starting Epoch 7 ---
Step 43: Loss = 0.2543, LR = 8.20e-04
Step 43 (Epoch 7): Training Loss = 0.1589
{'loss': 0.1589, 'grad_norm': 0.39286938309669495, 'learning_rate': 0.00084, 'epoch': 6.16}
Step 44: Loss = 0.1589, LR = 8.40e-04
Step 44 (Epoch 7): Training Loss = 0.1742
{'loss': 0.1742, 'grad_norm': 0.4055738151073456, 'learning_rate': 0.00086, 'epoch': 6.32}
Step 45: Loss = 0.1742, LR = 8.60e-04
Step 45 (Epoch 7): Training Loss = 0.1707
{'loss': 0.1707, 'grad_norm': 0.44473686814308167, 'learning_rate': 0.00088, 'epoch': 6.48}
Step 46: Loss = 0.1707, LR = 8.80e-04
Step 46 (Epoch 7): Training Loss = 0.1940
{'loss': 0.194, 'grad_norm': 0.4952729046344757, 'learning_rate': 0.0009000000000000001, 'epoch': 6.64}
Step 47: Loss = 0.1940, LR = 9.00e-04
Step 47 (Epoch 7): Training Loss = 0.1728
{'loss': 0.1728, 'grad_norm': 0.49198663234710693, 'learning_rate': 0.00092, 'epoch': 6.8}
Step 48: Loss = 0.1728, LR = 9.20e-04
Step 48 (Epoch 7): Training Loss = 0.1826
{'loss': 0.1826, 'grad_norm': 0.656932532787323, 'learning_rate': 0.00094, 'epoch': 6.96}
Step 49: Loss = 0.1826, LR = 9.40e-04
Step 49 (Epoch 7): Training Loss = 0.1643
{'loss': 0.1643, 'grad_norm': 1.0281381607055664, 'learning_rate': 0.00096, 'epoch': 7.0}

--- Starting Epoch 8 ---
Step 50: Loss = 0.1643, LR = 9.60e-04
Step 50 (Epoch 8): Training Loss = 0.1344
{'loss': 0.1344, 'grad_norm': 0.4577745497226715, 'learning_rate': 0.00098, 'epoch': 7.16}
Step 51: Loss = 0.1344, LR = 9.80e-04
Step 51 (Epoch 8): Training Loss = 0.1258
{'loss': 0.1258, 'grad_norm': 0.6218929290771484, 'learning_rate': 0.001, 'epoch': 7.32}
Step 52: Loss = 0.1258, LR = 1.00e-03
Step 52 (Epoch 8): Training Loss = 0.1581
{'loss': 0.1581, 'grad_norm': 0.47654345631599426, 'learning_rate': 0.000988888888888889, 'epoch': 7.48}
Step 53: Loss = 0.1581, LR = 9.89e-04
Step 53 (Epoch 8): Training Loss = 0.1146
{'loss': 0.1146, 'grad_norm': 0.3702333867549896, 'learning_rate': 0.0009777777777777777, 'epoch': 7.64}
Step 54: Loss = 0.1146, LR = 9.78e-04
Step 54 (Epoch 8): Training Loss = 0.1358
{'loss': 0.1358, 'grad_norm': 0.4651419520378113, 'learning_rate': 0.0009666666666666667, 'epoch': 7.8}
Step 55: Loss = 0.1358, LR = 9.67e-04
Step 55 (Epoch 8): Training Loss = 0.1464
{'loss': 0.1464, 'grad_norm': 0.6802827715873718, 'learning_rate': 0.0009555555555555556, 'epoch': 7.96}
Step 56: Loss = 0.1464, LR = 9.56e-04
Step 56 (Epoch 8): Training Loss = 0.1315
{'loss': 0.1315, 'grad_norm': 0.777159571647644, 'learning_rate': 0.0009444444444444445, 'epoch': 8.0}

--- Starting Epoch 9 ---
Step 57: Loss = 0.1315, LR = 9.44e-04
Step 57 (Epoch 9): Training Loss = 0.1102
{'loss': 0.1102, 'grad_norm': 0.4451862573623657, 'learning_rate': 0.0009333333333333333, 'epoch': 8.16}
Step 58: Loss = 0.1102, LR = 9.33e-04
Step 58 (Epoch 9): Training Loss = 0.1001
{'loss': 0.1001, 'grad_norm': 0.7488651871681213, 'learning_rate': 0.0009222222222222223, 'epoch': 8.32}
Step 59: Loss = 0.1001, LR = 9.22e-04
Step 59 (Epoch 9): Training Loss = 0.0997
{'loss': 0.0997, 'grad_norm': 0.2557210922241211, 'learning_rate': 0.0009111111111111111, 'epoch': 8.48}
Step 60: Loss = 0.0997, LR = 9.11e-04
Step 60 (Epoch 9): Training Loss = 0.1219
{'loss': 0.1219, 'grad_norm': 0.48297592997550964, 'learning_rate': 0.0009000000000000001, 'epoch': 8.64}
Step 61: Loss = 0.1219, LR = 9.00e-04
Step 61 (Epoch 9): Training Loss = 0.1184
{'loss': 0.1184, 'grad_norm': 0.3998047709465027, 'learning_rate': 0.0008888888888888888, 'epoch': 8.8}
Step 62: Loss = 0.1184, LR = 8.89e-04
Step 62 (Epoch 9): Training Loss = 0.1209
{'loss': 0.1209, 'grad_norm': 0.3410773277282715, 'learning_rate': 0.0008777777777777778, 'epoch': 8.96}
Step 63: Loss = 0.1209, LR = 8.78e-04
Step 63 (Epoch 9): Training Loss = 0.1477
{'loss': 0.1477, 'grad_norm': 0.9193637371063232, 'learning_rate': 0.0008666666666666667, 'epoch': 9.0}

--- Starting Epoch 10 ---
Step 64: Loss = 0.1477, LR = 8.67e-04
Step 64 (Epoch 10): Training Loss = 0.1057
{'loss': 0.1057, 'grad_norm': 0.2836475968360901, 'learning_rate': 0.0008555555555555556, 'epoch': 9.16}
Step 65: Loss = 0.1057, LR = 8.56e-04
Step 65 (Epoch 10): Training Loss = 0.1022
{'loss': 0.1022, 'grad_norm': 0.4434552788734436, 'learning_rate': 0.0008444444444444444, 'epoch': 9.32}
Step 66: Loss = 0.1022, LR = 8.44e-04
Step 66 (Epoch 10): Training Loss = 0.0978
{'loss': 0.0978, 'grad_norm': 0.29434362053871155, 'learning_rate': 0.0008333333333333334, 'epoch': 9.48}
Step 67: Loss = 0.0978, LR = 8.33e-04
Step 67 (Epoch 10): Training Loss = 0.1029
{'loss': 0.1029, 'grad_norm': 0.29025548696517944, 'learning_rate': 0.0008222222222222222, 'epoch': 9.64}
Step 68: Loss = 0.1029, LR = 8.22e-04
Step 68 (Epoch 10): Training Loss = 0.1009
{'loss': 0.1009, 'grad_norm': 0.35061728954315186, 'learning_rate': 0.0008111111111111111, 'epoch': 9.8}
Step 69: Loss = 0.1009, LR = 8.11e-04
Step 69 (Epoch 10): Training Loss = 0.1015
{'loss': 0.1015, 'grad_norm': 0.33616986870765686, 'learning_rate': 0.0008, 'epoch': 9.96}
Step 70: Loss = 0.1015, LR = 8.00e-04
Step 70 (Epoch 10): Training Loss = 0.0894
{'loss': 0.0894, 'grad_norm': 0.45235276222229004, 'learning_rate': 0.0007888888888888889, 'epoch': 10.0}

--- Starting Epoch 11 ---
Step 71: Loss = 0.0894, LR = 7.89e-04
Step 71 (Epoch 11): Training Loss = 0.0807
{'loss': 0.0807, 'grad_norm': 0.1704913228750229, 'learning_rate': 0.0007777777777777778, 'epoch': 10.16}
Step 72: Loss = 0.0807, LR = 7.78e-04
Step 72 (Epoch 11): Training Loss = 0.0863
{'loss': 0.0863, 'grad_norm': 0.2261567860841751, 'learning_rate': 0.0007666666666666667, 'epoch': 10.32}
Step 73: Loss = 0.0863, LR = 7.67e-04
Step 73 (Epoch 11): Training Loss = 0.0883
{'loss': 0.0883, 'grad_norm': 0.22009116411209106, 'learning_rate': 0.0007555555555555555, 'epoch': 10.48}
Step 74: Loss = 0.0883, LR = 7.56e-04
Step 74 (Epoch 11): Training Loss = 0.0833
{'loss': 0.0833, 'grad_norm': 0.3666321635246277, 'learning_rate': 0.0007444444444444445, 'epoch': 10.64}
Step 75: Loss = 0.0833, LR = 7.44e-04
Step 75 (Epoch 11): Training Loss = 0.0807
{'loss': 0.0807, 'grad_norm': 0.1782761812210083, 'learning_rate': 0.0007333333333333333, 'epoch': 10.8}
Step 76: Loss = 0.0807, LR = 7.33e-04
Step 76 (Epoch 11): Training Loss = 0.1001
{'loss': 0.1001, 'grad_norm': 0.3736232817173004, 'learning_rate': 0.0007222222222222222, 'epoch': 10.96}
Step 77: Loss = 0.1001, LR = 7.22e-04
Step 77 (Epoch 11): Training Loss = 0.0900
{'loss': 0.09, 'grad_norm': 0.3783593773841858, 'learning_rate': 0.0007111111111111111, 'epoch': 11.0}

--- Starting Epoch 12 ---
Step 78: Loss = 0.0900, LR = 7.11e-04
Step 78 (Epoch 12): Training Loss = 0.0869
{'loss': 0.0869, 'grad_norm': 0.19284369051456451, 'learning_rate': 0.0007, 'epoch': 11.16}
Step 79: Loss = 0.0869, LR = 7.00e-04
Step 79 (Epoch 12): Training Loss = 0.0807
{'loss': 0.0807, 'grad_norm': 0.1656375676393509, 'learning_rate': 0.000688888888888889, 'epoch': 11.32}
Step 80: Loss = 0.0807, LR = 6.89e-04
Step 80 (Epoch 12): Training Loss = 0.0798
{'loss': 0.0798, 'grad_norm': 0.15709049999713898, 'learning_rate': 0.0006777777777777778, 'epoch': 11.48}
Step 81: Loss = 0.0798, LR = 6.78e-04
Step 81 (Epoch 12): Training Loss = 0.0840
{'loss': 0.084, 'grad_norm': 0.3265475928783417, 'learning_rate': 0.0006666666666666666, 'epoch': 11.64}
Step 82: Loss = 0.0840, LR = 6.67e-04
Step 82 (Epoch 12): Training Loss = 0.0777
{'loss': 0.0777, 'grad_norm': 0.36184900999069214, 'learning_rate': 0.0006555555555555556, 'epoch': 11.8}
Step 83: Loss = 0.0777, LR = 6.56e-04
Step 83 (Epoch 12): Training Loss = 0.0854
{'loss': 0.0854, 'grad_norm': 0.25514236092567444, 'learning_rate': 0.0006444444444444444, 'epoch': 11.96}
Step 84: Loss = 0.0854, LR = 6.44e-04
Step 84 (Epoch 12): Training Loss = 0.0801
{'loss': 0.0801, 'grad_norm': 0.34108787775039673, 'learning_rate': 0.0006333333333333333, 'epoch': 12.0}

--- Starting Epoch 13 ---
Step 85: Loss = 0.0801, LR = 6.33e-04
Step 85 (Epoch 13): Training Loss = 0.0709
{'loss': 0.0709, 'grad_norm': 0.1333823800086975, 'learning_rate': 0.0006222222222222223, 'epoch': 12.16}
Step 86: Loss = 0.0709, LR = 6.22e-04
Step 86 (Epoch 13): Training Loss = 0.0659
{'loss': 0.0659, 'grad_norm': 0.11828427761793137, 'learning_rate': 0.0006111111111111112, 'epoch': 12.32}
Step 87: Loss = 0.0659, LR = 6.11e-04
Step 87 (Epoch 13): Training Loss = 0.0848
{'loss': 0.0848, 'grad_norm': 0.15376953780651093, 'learning_rate': 0.0006, 'epoch': 12.48}
Step 88: Loss = 0.0848, LR = 6.00e-04
Step 88 (Epoch 13): Training Loss = 0.0852
{'loss': 0.0852, 'grad_norm': 0.18488271534442902, 'learning_rate': 0.0005888888888888889, 'epoch': 12.64}
Step 89: Loss = 0.0852, LR = 5.89e-04
Step 89 (Epoch 13): Training Loss = 0.0801
{'loss': 0.0801, 'grad_norm': 0.399150550365448, 'learning_rate': 0.0005777777777777778, 'epoch': 12.8}
Step 90: Loss = 0.0801, LR = 5.78e-04
Step 90 (Epoch 13): Training Loss = 0.0807
{'loss': 0.0807, 'grad_norm': 0.16162040829658508, 'learning_rate': 0.0005666666666666667, 'epoch': 12.96}
Step 91: Loss = 0.0807, LR = 5.67e-04
Step 91 (Epoch 13): Training Loss = 0.0707
{'loss': 0.0707, 'grad_norm': 0.28115126490592957, 'learning_rate': 0.0005555555555555556, 'epoch': 13.0}

--- Starting Epoch 14 ---
Step 92: Loss = 0.0707, LR = 5.56e-04
Step 92 (Epoch 14): Training Loss = 0.0724
{'loss': 0.0724, 'grad_norm': 0.12274141609668732, 'learning_rate': 0.0005444444444444444, 'epoch': 13.16}
Step 93: Loss = 0.0724, LR = 5.44e-04
Step 93 (Epoch 14): Training Loss = 0.0715
{'loss': 0.0715, 'grad_norm': 0.21028698980808258, 'learning_rate': 0.0005333333333333334, 'epoch': 13.32}
Step 94: Loss = 0.0715, LR = 5.33e-04
Step 94 (Epoch 14): Training Loss = 0.0705
{'loss': 0.0705, 'grad_norm': 0.19217874109745026, 'learning_rate': 0.0005222222222222223, 'epoch': 13.48}
Step 95: Loss = 0.0705, LR = 5.22e-04
Step 95 (Epoch 14): Training Loss = 0.0794
{'loss': 0.0794, 'grad_norm': 0.16707539558410645, 'learning_rate': 0.0005111111111111111, 'epoch': 13.64}
Step 96: Loss = 0.0794, LR = 5.11e-04
Step 96 (Epoch 14): Training Loss = 0.0734
{'loss': 0.0734, 'grad_norm': 0.14790450036525726, 'learning_rate': 0.0005, 'epoch': 13.8}
Step 97: Loss = 0.0734, LR = 5.00e-04
Step 97 (Epoch 14): Training Loss = 0.0856
{'loss': 0.0856, 'grad_norm': 0.3122817873954773, 'learning_rate': 0.0004888888888888889, 'epoch': 13.96}
Step 98: Loss = 0.0856, LR = 4.89e-04
Step 98 (Epoch 14): Training Loss = 0.0760
{'loss': 0.076, 'grad_norm': 0.3256251811981201, 'learning_rate': 0.0004777777777777778, 'epoch': 14.0}

--- Starting Epoch 15 ---
Step 99: Loss = 0.0760, LR = 4.78e-04
Step 99 (Epoch 15): Training Loss = 0.0760
{'loss': 0.076, 'grad_norm': 0.13053517043590546, 'learning_rate': 0.00046666666666666666, 'epoch': 14.16}
Step 100: Loss = 0.0760, LR = 4.67e-04
Step 100 (Epoch 15): Training Loss = 0.0690
{'loss': 0.069, 'grad_norm': 0.11296168714761734, 'learning_rate': 0.00045555555555555556, 'epoch': 14.32}
Step 101: Loss = 0.0690, LR = 4.56e-04
Step 101 (Epoch 15): Training Loss = 0.0765
{'loss': 0.0765, 'grad_norm': 0.23342502117156982, 'learning_rate': 0.0004444444444444444, 'epoch': 14.48}
Step 102: Loss = 0.0765, LR = 4.44e-04
Step 102 (Epoch 15): Training Loss = 0.0683
{'loss': 0.0683, 'grad_norm': 0.12881077826023102, 'learning_rate': 0.00043333333333333337, 'epoch': 14.64}
Step 103: Loss = 0.0683, LR = 4.33e-04
Step 103 (Epoch 15): Training Loss = 0.0764
{'loss': 0.0764, 'grad_norm': 0.13654375076293945, 'learning_rate': 0.0004222222222222222, 'epoch': 14.8}
Step 104: Loss = 0.0764, LR = 4.22e-04
Step 104 (Epoch 15): Training Loss = 0.0740
{'loss': 0.074, 'grad_norm': 0.3305746018886566, 'learning_rate': 0.0004111111111111111, 'epoch': 14.96}
Step 105: Loss = 0.0740, LR = 4.11e-04
Step 105 (Epoch 15): Training Loss = 0.0842
{'loss': 0.0842, 'grad_norm': 0.2677192687988281, 'learning_rate': 0.0004, 'epoch': 15.0}

--- Starting Epoch 16 ---
Step 106: Loss = 0.0842, LR = 4.00e-04
Step 106 (Epoch 16): Training Loss = 0.0728
{'loss': 0.0728, 'grad_norm': 0.17713047564029694, 'learning_rate': 0.0003888888888888889, 'epoch': 15.16}
Step 107: Loss = 0.0728, LR = 3.89e-04
Step 107 (Epoch 16): Training Loss = 0.0690
{'loss': 0.069, 'grad_norm': 0.11537301540374756, 'learning_rate': 0.00037777777777777777, 'epoch': 15.32}
Step 108: Loss = 0.0690, LR = 3.78e-04
Step 108 (Epoch 16): Training Loss = 0.0705
{'loss': 0.0705, 'grad_norm': 0.12856459617614746, 'learning_rate': 0.00036666666666666667, 'epoch': 15.48}
Step 109: Loss = 0.0705, LR = 3.67e-04
Step 109 (Epoch 16): Training Loss = 0.0713
{'loss': 0.0713, 'grad_norm': 0.12432786822319031, 'learning_rate': 0.00035555555555555557, 'epoch': 15.64}
Step 110: Loss = 0.0713, LR = 3.56e-04
Step 110 (Epoch 16): Training Loss = 0.0689
{'loss': 0.0689, 'grad_norm': 0.11772990971803665, 'learning_rate': 0.0003444444444444445, 'epoch': 15.8}
Step 111: Loss = 0.0689, LR = 3.44e-04
Step 111 (Epoch 16): Training Loss = 0.0737
{'loss': 0.0737, 'grad_norm': 0.5640512704849243, 'learning_rate': 0.0003333333333333333, 'epoch': 15.96}
Step 112: Loss = 0.0737, LR = 3.33e-04
Step 112 (Epoch 16): Training Loss = 0.0667
{'loss': 0.0667, 'grad_norm': 0.273687481880188, 'learning_rate': 0.0003222222222222222, 'epoch': 16.0}

--- Starting Epoch 17 ---
Step 113: Loss = 0.0667, LR = 3.22e-04
Step 113 (Epoch 17): Training Loss = 0.0711
{'loss': 0.0711, 'grad_norm': 0.11535844951868057, 'learning_rate': 0.0003111111111111111, 'epoch': 16.16}
Step 114: Loss = 0.0711, LR = 3.11e-04
Step 114 (Epoch 17): Training Loss = 0.0731
{'loss': 0.0731, 'grad_norm': 0.19179755449295044, 'learning_rate': 0.0003, 'epoch': 16.32}
Step 115: Loss = 0.0731, LR = 3.00e-04
Step 115 (Epoch 17): Training Loss = 0.0667
{'loss': 0.0667, 'grad_norm': 0.11508569866418839, 'learning_rate': 0.0002888888888888889, 'epoch': 16.48}
Step 116: Loss = 0.0667, LR = 2.89e-04
Step 116 (Epoch 17): Training Loss = 0.0673
{'loss': 0.0673, 'grad_norm': 0.1228794977068901, 'learning_rate': 0.0002777777777777778, 'epoch': 16.64}
Step 117: Loss = 0.0673, LR = 2.78e-04
Step 117 (Epoch 17): Training Loss = 0.0693
{'loss': 0.0693, 'grad_norm': 0.259919673204422, 'learning_rate': 0.0002666666666666667, 'epoch': 16.8}
Step 118: Loss = 0.0693, LR = 2.67e-04
Step 118 (Epoch 17): Training Loss = 0.0706
{'loss': 0.0706, 'grad_norm': 0.14171633124351501, 'learning_rate': 0.00025555555555555553, 'epoch': 16.96}
Step 119: Loss = 0.0706, LR = 2.56e-04
Step 119 (Epoch 17): Training Loss = 0.0777
{'loss': 0.0777, 'grad_norm': 0.3270609974861145, 'learning_rate': 0.00024444444444444443, 'epoch': 17.0}

--- Starting Epoch 18 ---
Step 120: Loss = 0.0777, LR = 2.44e-04
Step 120 (Epoch 18): Training Loss = 0.0657
{'loss': 0.0657, 'grad_norm': 0.11843700706958771, 'learning_rate': 0.00023333333333333333, 'epoch': 17.16}
Step 121: Loss = 0.0657, LR = 2.33e-04
Step 121 (Epoch 18): Training Loss = 0.0683
{'loss': 0.0683, 'grad_norm': 0.10698538273572922, 'learning_rate': 0.0002222222222222222, 'epoch': 17.32}
Step 122: Loss = 0.0683, LR = 2.22e-04
Step 122 (Epoch 18): Training Loss = 0.0698
{'loss': 0.0698, 'grad_norm': 0.12708276510238647, 'learning_rate': 0.0002111111111111111, 'epoch': 17.48}
Step 123: Loss = 0.0698, LR = 2.11e-04
Step 123 (Epoch 18): Training Loss = 0.0689
{'loss': 0.0689, 'grad_norm': 0.13218137621879578, 'learning_rate': 0.0002, 'epoch': 17.64}
Step 124: Loss = 0.0689, LR = 2.00e-04
Step 124 (Epoch 18): Training Loss = 0.0679
{'loss': 0.0679, 'grad_norm': 0.13252437114715576, 'learning_rate': 0.00018888888888888888, 'epoch': 17.8}
Step 125: Loss = 0.0679, LR = 1.89e-04
Step 125 (Epoch 18): Training Loss = 0.0649
{'loss': 0.0649, 'grad_norm': 0.10412780940532684, 'learning_rate': 0.00017777777777777779, 'epoch': 17.96}
Step 126: Loss = 0.0649, LR = 1.78e-04
Step 126 (Epoch 18): Training Loss = 0.0793
{'loss': 0.0793, 'grad_norm': 0.2909844219684601, 'learning_rate': 0.00016666666666666666, 'epoch': 18.0}

--- Starting Epoch 19 ---
Step 127: Loss = 0.0793, LR = 1.67e-04
Step 127 (Epoch 19): Training Loss = 0.0656
{'loss': 0.0656, 'grad_norm': 0.11112646758556366, 'learning_rate': 0.00015555555555555556, 'epoch': 18.16}
Step 128: Loss = 0.0656, LR = 1.56e-04
Step 128 (Epoch 19): Training Loss = 0.0695
{'loss': 0.0695, 'grad_norm': 0.13259950280189514, 'learning_rate': 0.00014444444444444444, 'epoch': 18.32}
Step 129: Loss = 0.0695, LR = 1.44e-04
Step 129 (Epoch 19): Training Loss = 0.0678
{'loss': 0.0678, 'grad_norm': 0.10418933629989624, 'learning_rate': 0.00013333333333333334, 'epoch': 18.48}
Step 130: Loss = 0.0678, LR = 1.33e-04
Step 130 (Epoch 19): Training Loss = 0.0698
{'loss': 0.0698, 'grad_norm': 0.1246301606297493, 'learning_rate': 0.00012222222222222221, 'epoch': 18.64}
Step 131: Loss = 0.0698, LR = 1.22e-04
Step 131 (Epoch 19): Training Loss = 0.0653
{'loss': 0.0653, 'grad_norm': 0.1149287298321724, 'learning_rate': 0.0001111111111111111, 'epoch': 18.8}
Step 132: Loss = 0.0653, LR = 1.11e-04
Step 132 (Epoch 19): Training Loss = 0.0656
{'loss': 0.0656, 'grad_norm': 0.14127187430858612, 'learning_rate': 0.0001, 'epoch': 18.96}
Step 133: Loss = 0.0656, LR = 1.00e-04
Step 133 (Epoch 19): Training Loss = 0.0690
{'loss': 0.069, 'grad_norm': 0.23056121170520782, 'learning_rate': 8.888888888888889e-05, 'epoch': 19.0}

--- Starting Epoch 20 ---
Step 134: Loss = 0.0690, LR = 8.89e-05
Step 134 (Epoch 20): Training Loss = 0.0659
{'loss': 0.0659, 'grad_norm': 0.10883455723524094, 'learning_rate': 7.777777777777778e-05, 'epoch': 19.16}
Step 135: Loss = 0.0659, LR = 7.78e-05
Step 135 (Epoch 20): Training Loss = 0.0678
{'loss': 0.0678, 'grad_norm': 0.11875111609697342, 'learning_rate': 6.666666666666667e-05, 'epoch': 19.32}
Step 136: Loss = 0.0678, LR = 6.67e-05
Step 136 (Epoch 20): Training Loss = 0.0656
{'loss': 0.0656, 'grad_norm': 0.11139438301324844, 'learning_rate': 5.555555555555555e-05, 'epoch': 19.48}
Step 137: Loss = 0.0656, LR = 5.56e-05
Step 137 (Epoch 20): Training Loss = 0.0640
{'loss': 0.064, 'grad_norm': 0.1153782308101654, 'learning_rate': 4.4444444444444447e-05, 'epoch': 19.64}
Step 138: Loss = 0.0640, LR = 4.44e-05
Step 138 (Epoch 20): Training Loss = 0.0661
{'loss': 0.0661, 'grad_norm': 0.11887294799089432, 'learning_rate': 3.3333333333333335e-05, 'epoch': 19.8}
Step 139: Loss = 0.0661, LR = 3.33e-05
Step 139 (Epoch 20): Training Loss = 0.0671
{'loss': 0.0671, 'grad_norm': 0.12253063917160034, 'learning_rate': 2.2222222222222223e-05, 'epoch': 19.96}
Step 140: Loss = 0.0671, LR = 2.22e-05
Step 140 (Epoch 20): Training Loss = 0.0651
{'loss': 0.0651, 'grad_norm': 0.2491113394498825, 'learning_rate': 1.1111111111111112e-05, 'epoch': 20.0}
{'train_runtime': 519.8844, 'train_samples_per_second': 3.847, 'train_steps_per_second': 0.269, 'train_loss': 0.43919429826949324, 'epoch': 20.0}
==================================================
Saving adapter...
Training complete! Adapter saved to /workspace/NLP_Project/adapters/ep20_bs2_lr1e-3_r8_layers10
Loading test data...
Successfully loaded 100 items from JSON file
Evaluating on 100 samples
Loading model...
Generating predictions...

--- Sample 1 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what country is Normandy located?
Expected: France
Predicted: France

--- Sample 2 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When were the Normans in Normandy?
Expected: 10th and 11th centuries
Predicted: 10th and 11th centuries

--- Sample 3 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: From which countries did the Norse originate?
Expected: Denmark, Iceland and Norway
Predicted: Denmark, Iceland and Norway

--- Sample 4 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the Norse leader?
Expected: Rollo
Predicted: Rollo

--- Sample 5 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What century did the Normans first gain their separate identity?
Expected: 10th century
Predicted: 10th century

--- Sample 6 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the duke in the battle of Hastings?
Expected: William the Conqueror
Predicted: William the Conqueror

--- Sample 7 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruled the duchy of Normandy
Expected: Richard I
Predicted: Richard I

--- Sample 8 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What religion were the Normans
Expected: Catholic
Predicted: Catholic

--- Sample 9 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the original meaning of the word Norman?
Expected: Viking
Predicted: Viking

--- Sample 10 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Latin version of the word Norman first recorded?
Expected: 9th century
Predicted: 9th century

--- Sample 11 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Duchy of Normandy founded?
Expected: 911
Predicted: 911

--- Sample 12 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Rollo sign the treaty of Saint-Clair-sur-Epte with?
Expected: King Charles III
Predicted: King Charles III

--- Sample 13 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What river originally bounded the Duchy
Expected: Seine
Predicted: Seine

--- Sample 14 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who upon arriving gave the original viking settlers a common identity?
Expected: Rollo
Predicted: Rollo

--- Sample 15 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the Norman religion?
Expected: Catholicism
Predicted: Catholicism

--- Sample 16 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What part of France were the Normans located?
Expected: north
Predicted: north

--- Sample 17 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was one of the Norman's major exports?
Expected: fighting horsemen
Predicted: fighting horsemen

--- Sample 18 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the Normans' main enemy in Italy, the Byzantine Empire and Armenia?
Expected: Seljuk Turks
Predicted: Seljuk Turks

--- Sample 19 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Herve serve as a Byzantine general?
Expected: 1050s
Predicted: 1050s

--- Sample 20 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Robert Crispin go up against the Turks?
Expected: 1060s
Predicted: 1060s

--- Sample 21 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruined Roussel de Bailleul's plans for an independent state?
Expected: Alexius Komnenos
Predicted: Alexius Komnenos

--- Sample 22 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of the Norman castle?
Expected: Afranji
Predicted: Afranji

--- Sample 23 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the leader when the Franks entered the Euphrates valley?
Expected: Oursel
Predicted: Oursel

--- Sample 24 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did the Normans team up with in Anatolia?
Expected: Turkish forces
Predicted: Turkish forces

--- Sample 25 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What were the origins of the Raouliii family?
Expected: Norman mercenary
Predicted: Norman mercenary

--- Sample 26 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of the count of Apulia 
Expected: Robert Guiscard
Predicted: Robert Guiscard

--- Sample 27 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Dyrrachium  fall to the Normans?
Expected: 1082
Predicted: 1082

--- Sample 28 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How many men were in Robert's army?
Expected: 30,000
Predicted: 30,000

--- Sample 29 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did the Normans and Byzantines sign the peace treaty?
Expected: Deabolis
Predicted: Deabolis

--- Sample 30 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Robert's son?
Expected: Bohemond
Predicted: Bohemond

--- Sample 31 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What river was Petrela located by?
Expected: Deabolis
Predicted: Deabolis

--- Sample 32 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the Normans attack Dyrrachium?
Expected: 1185
Predicted: 1185

--- Sample 33 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the naval base called?
Expected: Dyrrachium
Predicted: Dyrrachium

--- Sample 34 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where was Dyrrachium located?
Expected: the Adriatic
Predicted: the Adriatic

--- Sample 35 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Emma Marry?
Expected: King Ethelred II
Predicted: King Ethelred II

--- Sample 36 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Emma's brother?
Expected: Duke Richard II
Predicted: Duke Richard II

--- Sample 37 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: To where did Ethelred flee?
Expected: Normandy
Predicted: Normandy

--- Sample 38 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who kicked Ethelred out?
Expected: Sweyn Forkbeard
Predicted: Sweyn Forkbeard

--- Sample 39 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Edward the Confessor's half-brother?
Expected: Harthacnut
Predicted: Harthacnut

--- Sample 40 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did Edward return?
Expected: 1041
Predicted: 1041

--- Sample 41 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Edward make archbishop of Canterbury?
Expected: Robert of Jumièges
Predicted: Robert of Jumièges

--- Sample 42 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did Harold II die?
Expected: Battle of Hastings
Predicted: Battle of Hastings

--- Sample 43 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who killed Harold II? 
Expected: William II
Predicted: William II

--- Sample 44 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was the Battle of Hastings?
Expected: 1066
Predicted: 1066

--- Sample 45 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the ruling class ahead of the Normans?
Expected: Anglo-Saxons
Predicted: Anglo-Saxons

--- Sample 46 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the Anglo-Norman language's final form?
Expected: Modern English
Predicted: Modern English

--- Sample 47 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what year did the Norman's invade at Bannow Bay?
Expected: 1169
Predicted: 1169

--- Sample 48 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What country did the Normans invade in 1169?
Expected: Ireland
Predicted: Ireland

--- Sample 49 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What culture did the Normans combine with in Ireland?
Expected: Irish
Predicted: Irish

--- Sample 50 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Margaret's brother?
Expected: Edgar
Predicted: Edgar

--- Sample 51 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Margaret's husband?
Expected: King Malcolm III of Scotland
Predicted: King Malcolm III of Scotland

--- Sample 52 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When was Scotland invaded by William?
Expected: 1072
Predicted: 1072

--- Sample 53 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was the hostage?
Expected: Duncan
Predicted: Duncan

--- Sample 54 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who did Alexander I marry?
Expected: Sybilla of Normandy
Predicted: Sybilla of Normandy

--- Sample 55 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What culture's arrival in Scotland is know as the "Davidian Revolution"?
Expected: Norman
Predicted: Norman

--- Sample 56 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where was Ralph earl of?
Expected: Hereford
Predicted: Hereford

--- Sample 57 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Ralph in charge of being at war with?
Expected: the Welsh
Predicted: the Welsh

--- Sample 58 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who made Ralph earl?
Expected: Edward the Confessor
Predicted: Edward the Confessor

--- Sample 59 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What country was under the control of Norman barons?
Expected: Wales
Predicted: Wales

--- Sample 60 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What year did Roger de Tosny fail to accomplish what he set out to do?
Expected: 1018
Predicted: 1018

--- Sample 61 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was in charge of the papal army in the War of Barbastro?
Expected: William of Montreuil
Predicted: William of Montreuil

--- Sample 62 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the Siege of Antioch take place?
Expected: 1097
Predicted: 1097

--- Sample 63 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What was the name of Bohemond's nephew?
Expected: Tancred
Predicted: Tancred

--- Sample 64 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What major conquest did Tancred play a roll in?
Expected: Jerusalem
Predicted: Jerusalem

--- Sample 65 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How long did Western Europe control Cyprus?
Expected: 380 years
Predicted: 380 years

--- Sample 66 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What ruined Richard's plans to reach Acre?
Expected: a storm
Predicted: a storm

--- Sample 67 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Richard's fiancee?
Expected: Berengaria
Predicted: Berengaria

--- Sample 68 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What year did the storm hit Richard's fleet?
Expected: 1191
Predicted: 1191

--- Sample 69 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who ruled Cyprus in 1191?
Expected: Isaac Komnenos
Predicted: Isaac Komnenos

--- Sample 70 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who was Guy's Rival?
Expected: Conrad of Montferrat
Predicted: Conrad of Montferrat

--- Sample 71 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What were Isaac's chains made out of?
Expected: silver
Predicted: silver

--- Sample 72 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who led Richard's troops when Cyprus was conquered?
Expected: Guy de Lusignan
Predicted: Guy de Lusignan

--- Sample 73 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What continent are the Canarian Islands off the coast of?
Expected: Africa
Predicted: Africa

--- Sample 74 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who became the King of the Canary Islands?
Expected: Bethencourt
Predicted: Bethencourt

--- Sample 75 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who bought the rights?
Expected: Enrique Pérez de Guzmán
Predicted: Enrique Pérez de Guzmán

--- Sample 76 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who sold the rights?
Expected: Maciot de Bethencourt
Predicted: Maciot de Bethencourt

--- Sample 77 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where are Jersey and Guernsey
Expected: Channel Islands
Predicted: Channel Islands

--- Sample 78 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: How many customaries does Norman customary law have?
Expected: two
Predicted: two

--- Sample 79 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the Norman architecture idiom?
Expected: Romanesque
Predicted: Romanesque

--- Sample 80 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What kind of arches does Norman architecture have?
Expected: rounded
Predicted: rounded

--- Sample 81 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What architecture type came after Norman in England?
Expected: Early Gothic
Predicted: Early Gothic

--- Sample 82 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What architecture type came before Norman in England?
Expected: Anglo-Saxon
Predicted: Anglo-Saxon

--- Sample 83 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What place had the Norman Arab architectural style?
Expected: Sicily
Predicted: Sicily

--- Sample 84 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When did the church reform begin?
Expected: early 11th century
Predicted: early 11th century

--- Sample 85 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who used the church to unify themselves?
Expected: dukes
Predicted: dukes

--- Sample 86 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: When were the French wars of religion?
Expected: 16th century
Predicted: 16th century

--- Sample 87 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What kind of needlework was used in the creation of the Bayeux Tapestry?
Expected: embroidery
Predicted: embroidery

--- Sample 88 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is Norman art's most well known piece?
Expected: Bayeux Tapestry
Predicted: Bayeux Tapestry

--- Sample 89 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who commissioned the Tapestry?
Expected: Odo
Predicted: Odo

--- Sample 90 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the most important type of Norman art preserved in churches?
Expected: mosaics
Predicted: mosaics

--- Sample 91 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: In what century did important classical music developments occur in Normandy?
Expected: 11th
Predicted: 11th

--- Sample 92 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who were the two abbots at Fécamp Abbey?
Expected: William of Volpiano and John of Ravenna
Predicted: William of Volpiano and John of Ravenna

--- Sample 93 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Where did the monks flee to?
Expected: southern Italy
Predicted: southern Italy

--- Sample 94 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What monastery did the Saint-Evroul monks establish in Italy?
Expected: Latin monastery at Sant'Eufemia.
Predicted: Latin monastery at Sant'Eufemia

--- Sample 95 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: Who patronized the monks in Italy? 
Expected: Robert Guiscard
Predicted: Robert Guiscard

--- Sample 96 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What tradition were the Saint-Evroul monks known for?
Expected: singing
Predicted: singing

--- Sample 97 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?
Expected: Computational complexity theory
Predicted: Computational complexity theory

--- Sample 98 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: By what main attribute are computational problems classified utilizing computational complexity theory? 
Expected: inherent difficulty
Predicted: inherent difficulty

--- Sample 99 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What is the term for a task that generally lends itself to being solved by a computer?
Expected: computational problems
Predicted: computational problems

--- Sample 100 ---
Question: Answer the question based on the given documents. Only give me the answer and do not output any other words.

Question: What measure of a computational problem broadly defines the inherent difficulty of the solution?
Expected: if its solution requires significant resources
Predicted: if its solution requires significant resources
Evaluating...

=== Benchmark Results ===
Exact Accuracy: 0.990
Partial Accuracy: 1.000
Exact Matches: 99/100
Partial Matches: 1/100

Detailed results saved to benchmark_results.json
Starting LoRA training with RTX 3090 optimized settings...
Epochs: 20, Batch size: 2, Learning rate: 0.001
Command: python train_lora_optimized.py --model_name Qwen/Qwen3-8B --epochs 20 --batch_size 2 --learning_rate 0.001 --adapter_r 8 --adapter_layers 10 --output_dir /workspace/NLP_Project/adapters/ep20_bs2_lr1e-3_r8_layers10

Training completed successfully!
